# -*- coding: utf-8 -*-
"""言語処理

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xVFugMblk6IVN93lWe5PdB0IqaWfHglX

自然言語処理を始めるにあたり　まずは必要なパッケージを入れます
"""

# Mecabを使用するとエラーが出るため一時的に中止
#!pip3 install mecab-python3
import random
import time
import math
print("done!")

"""次に　自然言語処理に使うテキストを用意します。
例としてなろう小説のtextを使ってみましょう。

マウントしてみます

※**google ドライブを使用しない場合は次二つのセルをスキップしてください**
"""

#マウント
from google.colab import drive
drive.mount('/content/drive')

"""適切にマウントされたか確かめます
※**google ドライブを使用しない場合はこのセルをスキップしてください**
"""

# ローカルディレクトリからファイル読み込み
start=time.time()
path = "output.txt"
f = open(path,encoding="UTF-8")
text=f.read()
le=len(text)
print("文章の長さ:"+str(len(text)))
print("最初の50文字\n")
for i in range(50):
  print(text[i],end="")
print("\n")
print("time: "+str(time.time()-start))

"""※**google drive以外で実行する場合はこちら**。上二つの代わり"""

# ネットからファイル読み込み
start=time.time()
import urllib
url="https://2019-aut-tue-5-software.s3-ap-northeast-1.amazonaws.com/output.txt"
res = urllib.request.urlopen(url=url)
text=res.read().decode('utf-8')
le=len(text)
print("文章の長さ:"+str(len(text)))
print("最初の50文字\n")
for i in range(50):
  print(text[i],end="")
print("\n")
print("time: "+str(time.time()-start))

"""準備ができました。　早速単語に分けてみましょう"""

# Mecabを使用するとエラーが出るため一時的に中止
#import MeCab
#tagger = MeCab.Tagger("-Owakati")
#str_output = tagger.parse(text)
#print(str_output)
#print(type(str_output))

"""次に単語を辞書に突っ込んでいきます"""

start=time.time()

# 単語を辞書に突っ込む関数
def add_word(dictionary,word):
  if(word in dictionary):
    dictionary[word]+=1
  else:
    dictionary[word]=1

# 改行で区切る...ってこれ意味あるのかとかあとで思った
text2=text.splitlines()
words={}
p=0
# 一行にある単語を分割して辞書に突っ込む
for i in range(len(text2)):
  word = text2[i].split(" ")
  for j in word:
    p+=1
    add_word(words,j)
# 辞書のキーを取得
key_dict=words.keys()
# キーをリストに変換
keys=list(key_dict)
print("文字数　："+str(le))
print("総単語数  : "+str(p))
print("単語の種類: "+str(len(words)))

print("\n")
print("time: "+str(time.time()-start))

"""辞書に単語を突っ込むのは終了しました。
続いて検索時間を見てみましょう。

ランダムにm個選んで検索　をn回やって平均をとってみます
"""

# 単語の出現回数順に n個表示
def show_table(n):
  print("頻出単語を上位から "+str(n)+" 個表示します")
  score_sorted = sorted(words.items(), key=lambda x:-x[1])
  for i in range(n):
    print(score_sorted[i])

# 単語の検索時間を測定する。
def count_time(n,m):
  start=time.time()

  total=0
  count=len(keys)
  s="a"
  for i in range(n):
    for j in range(m):
      rand=random.random()
      rand=math.floor(rand*(count-1))
      s=words[keys[rand]]
      #print(str(keys[rand])+" : "+str(words[keys[rand]]))
  print(str(n*m)+" 回単語を検索しました。")
  print("total: "+str(time.time()-start))
  print(str(m)+" 回の検索にかかった平均時間("+str(n)+"回施行)")
  print("average: "+str((time.time()-start)/n))
count_time(100,1000)
show_table(100)